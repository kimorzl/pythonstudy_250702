{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613c5446-fb70-4776-8f21-b4dab6830a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토\n",
      "잔금대출에도 DTI 규제 적용 검토\n"
     ]
    }
   ],
   "source": [
    "import requests #requests라는 라이브러리 객체를 가져온다\n",
    "from bs4 import BeautifulSoup #bs4라는 라이브러리 객체 내 BeautifulSoup이라는 함수를 가져온다.\n",
    "\n",
    "res = requests.get(\"https://v.daum.net/v/20170615203441266\") #찾아오고자하는 웹 페이지에 대한 응답값 res라는 변수에 requests 라이브러리를 통해 get함수를 사용해 원하는 값을 가져오겠다.\n",
    "soup = BeautifulSoup(res.content, \"html.parser\") #res.content 자료를 html.parser를 이용해 읽기 쉬운 문서로 만들어 줘.\n",
    "\n",
    "#print(soup) #읽기 쉽게 만든 그 내용을 출력해줘.\n",
    "\n",
    "mydata = soup.find(\"h3\", class_ = \"tit_view\") #class를 디폴트값으로 읽어오기때문에 그 안에 매칭되는 다른 값을 찾음\n",
    "print(mydata.string) #크롤링해온 데이터에서 태그를 제외한 내용만 출력해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d74eb460-bfa6-4339-a871-dc8313102c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017. 6. 15. 20:34\n",
      "2017. 6. 15. 20:34\n",
      "2017. 6. 15. 20:34\n"
     ]
    }
   ],
   "source": [
    "import requests #requests라는 라이브러리 객체를 가져온다\n",
    "from bs4 import BeautifulSoup #bs4라는 라이브러리 객체 내 BeautifulSoup이라는 함수를 가져온다.\n",
    "\n",
    "res = requests.get(\"https://v.daum.net/v/20170615203441266\") #찾아오고자하는 웹 페이지에 대한 응답값 res라는 변수에 requests 라이브러리를 통해 get함수를 사용해 원하는 값을 가져오겠다.\n",
    "soup = BeautifulSoup(res.content, \"html.parser\") #res.content 자료를 html.parser를 이용해 읽기 쉬운 문서로 만들어 줘.\n",
    "\n",
    "#print(soup) #읽기 쉽게 만든 그 내용을 출력해줘.\n",
    "\n",
    "date = soup.find(\"span\", class_=\"num_date\")#class를 디폴트값으로 읽어오기때문에 그 안에 매칭되는 다른 값을 찾음\n",
    "print(date.string) #크롤링해온 데이터에서 태그를 제외한 내용만 출력해줘\n",
    "\n",
    "date1 = soup.find(\"span\", attrs={\"class\":\"num_date\"})\n",
    "print(date1.string)\n",
    "\n",
    "mydata2 = soup.find_all(\"span\", class_=\"txt_info\")\n",
    "print(mydata2[1].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "615b2a36-0824-4899-a815-61cf4b76d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 클래스 소개</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 블로그 개발 필요한 준비물 준비하기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 초간단 페이지 만들어보기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 이쁘게 테마 적용해보기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지\n",
      "          만들기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지\n",
      "          꾸며보기</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 필요한 프로그램 설치 시연 [5]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 데이터를 엑셀 파일로 만들기 [9]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) -     나대신 주기적으로 파이썬 프로그램\n",
      "          실행하기 [7]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "          [12]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]</a>\n",
      "</li>, <li class=\"course\">\n",
      "<a href=\"#\">(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버\n",
      "          블로그/트위터에 홍보하기 [412]</a>\n",
      "</li>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m prac \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(prac)\n\u001b[1;32m---> 12\u001b[0m prac1 \u001b[38;5;241m=\u001b[39m prac\u001b[38;5;241m.\u001b[39mget_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma herf=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(prac1)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2435\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "#https://crawlingtest.netlify.app/문서에서 li태그이면서 course라는 클래스값을 가지고 있는 요소들을 크롤링해서 주피터 노트북에 출력해주세요.\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "#print(soup)\n",
    "\n",
    "prac = soup.find_all(\"li\",class_=\"course\")\n",
    "print(prac)\n",
    "\n",
    "prac1 = prac.get_text(\"a herf='#'\")\n",
    "print(prac1)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
