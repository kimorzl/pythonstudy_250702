{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea266fa-462a-4570-b786-b68cd6f02f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#li태그, course클래스를 가지고 있는 text값을 가져오세요.\n",
    "#https://crawlingtest.netlify.app/\n",
    "\n",
    "#웹 사이트 구조가 복잡한 경우 크롤링하기 어려움\n",
    "#동적인 구조의 사이트는 크롤링하기 어려움course클래스를 가지고 있는 text값을 가져오세요.\n",
    "#https://crawlingtest.netlify.app/\n",
    "\n",
    "#웹 사이트 구조가 복잡한 경우 크롤링하기 어려움\n",
    "#동적인 구조의 사이트는 크롤링하기 어려움\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b06ef984-f9a3-4ee9-bcec-7aa558801ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(왕초보) - 클래스 소개\n",
      "\n",
      "\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "\n",
      "\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "\n",
      "\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "\n",
      "\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "\n",
      "\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지\n",
      "          만들기\n",
      "\n",
      "\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지\n",
      "          꾸며보기\n",
      "\n",
      "\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "\n",
      "\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "\n",
      "\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "\n",
      "\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "\n",
      "\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램\n",
      "          실행하기 [7]\n",
      "\n",
      "\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "\n",
      "\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "          [12]\n",
      "\n",
      "\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "\n",
      "\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버\n",
      "          블로그/트위터에 홍보하기 [412]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "#print(res)\n",
    "\n",
    "soup=BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "#print(soup)\n",
    "\n",
    "titles = soup.find_all(\"li\",class_=\"course\")\n",
    "#print(titles)\n",
    "\n",
    "for title in titles :\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e6858ba-434c-4177-a36c-6b61ac07b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(왕초보) - 클래스 소개\n",
      "\n",
      "\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "\n",
      "\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "\n",
      "\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "\n",
      "\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "\n",
      "\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지\n",
      "          만들기\n",
      "\n",
      "\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지\n",
      "          꾸며보기\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "soup=BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "#ul태그 => un-order list, ol태그 => oder list : 둘다 단독으로 사용할 수 없고 하위 태그들이 필요함\n",
    "\n",
    "\n",
    "# 파이썬을 활용해 특정 웹사이트내 요소를 크롤링해오면 해당 값의 자료형태는 객체의 형태를 띄게 됨\n",
    "# 객체의 형태를 띄게 되었을때 객체의 속성, 메서드 함수를 사용할 수 있게 됨.\n",
    "#section = soup.find(\"ul\",id=\"hobby_course_list\").find_all(\"li\",class_=\"course\") #메서드 체이닝 기법, 첫번째 메서드가 끝나고 두번째 메서드가 돌아가는 구조\n",
    "#print(section)\n",
    "section = soup.find(\"ul\",id=\"hobby_course_list\")\n",
    "titles = section.find_all(\"li\",class_=\"course\")\n",
    "\n",
    "for item in titles:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6fbacf-1926-4c83-a9ad-852b87ca5f8b",
   "metadata": {},
   "source": [
    "#### 파이썰 크롤링 미션\n",
    "- https://crawlingtest.netlify.app/ 해당 사이트에서 course라는 클래스 값을 가지고 있는 li태그 내부 텍스트를 출력하세요.\n",
    "  * 단, 난이도 (단계)를 제거한 설명 문항만 출력해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2ba239-48b8-4b45-9115-e28a16505f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 클래스 소개\n",
      "\n",
      " 블로그 개발 필요한 준비물 준비하기\n",
      "\n",
      " Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "\n",
      " 초간단 페이지 만들어보기\n",
      "\n",
      " 이쁘게 테마 적용해보기\n",
      "\n",
      " 마크다운 기초 이해하고, 실제 나만의 블로그 페이지\n",
      "          만들기\n",
      "\n",
      " 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지\n",
      "          꾸며보기\n",
      "\n",
      " 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "\n",
      " 필요한 프로그램 설치 시연 [5]\n",
      "\n",
      " 데이터를 엑셀 파일로 만들기 [9]\n",
      "\n",
      "     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "\n",
      "     나대신 주기적으로 파이썬 프로그램\n",
      "          실행하기 [7]\n",
      "\n",
      " 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "\n",
      " 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "          [12]\n",
      "\n",
      " 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "\n",
      " 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버\n",
      "          블로그/트위터에 홍보하기 [412]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이트를 크롤링해 자료를 받는다.\n",
    "# 보기 좋은 형태로 데이터를 바꾼다\n",
    "# 그 중 il태그, course 태그에 해당하는 데이터만 추출한다\n",
    "# 태그 데이터는 제외하고 텍스트만 정리한다\n",
    "# 정리한 텍스트 중 (), - 와같은 부가적 데이터는 없애고 정리한 후 출력한다.\n",
    "\n",
    "#풀이1 내가한 풀이\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "#print(res)\n",
    "res2 = BeautifulSoup(res.content, \"html.parser\")\n",
    "#print(res2)\n",
    "\n",
    "titles = res2.find_all(\"li\",\"course\")\n",
    "#print(titles)\n",
    "\n",
    "for item in titles:\n",
    "    title2 = item.get_text()\n",
    "    title3 = title2.split(\"-\")\n",
    "    print(title3[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88ab6035-794f-41f2-ba41-c7d6b6e002ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스소개\n",
      "블로그개발필요한준비물준비하기\n",
      "Githubpages설정해서블로그첫페이지만들어보기\n",
      "초간단페이지만들어보기\n",
      "이쁘게테마적용해보기\n",
      "마크다운기초이해하고,실제나만의블로그페이지만들기\n",
      "다양한마크다운기법익혀보며,나만의블로그페이지꾸며보기\n",
      "강사가실제사용하는자동프로그램소개[2]\n",
      "필요한프로그램설치시연[5]\n",
      "데이터를엑셀파일로만들기[9]\n",
      "엑셀파일이쁘게!이쁘게![8]\n",
      "나대신주기적으로파이썬프로그램실행하기[7]\n",
      "파이썬으로슬랙(slack)메신저에글쓰기[40]\n",
      "웹사이트변경사항주기적으로체크해서,메신저로알람주기[12]\n",
      "네이버API사용해서,블로그에글쓰기[42]\n",
      "자동으로쿠팡파트너스API로가져온상품정보,네이버블로그/트위터에홍보하기[412]\n"
     ]
    }
   ],
   "source": [
    "#풀이2 선생님 풀이\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "titles = soup.find_all(\"li\",\"course\")\n",
    "\n",
    "for title in titles :\n",
    "    print(title.get_text().split(\"-\")[1].replace(\"\\n\",\" \").replace(\" \",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03217e5c-5fbf-4cd8-9097-dd4eb2a2d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 클래스소개\n",
      "2 블로그개발필요한준비물준비하기\n",
      "3 Githubpages설정해서블로그첫페이지만들어보기\n",
      "4 초간단페이지만들어보기\n",
      "5 이쁘게테마적용해보기\n",
      "6 마크다운기초이해하고,실제나만의블로그페이지만들기\n",
      "7 다양한마크다운기법익혀보며,나만의블로그페이지꾸며보기\n",
      "8 강사가실제사용하는자동프로그램소개\n",
      "9 필요한프로그램설치시연\n",
      "10 데이터를엑셀파일로만들기\n",
      "11 엑셀파일이쁘게!이쁘게!\n",
      "12 나대신주기적으로파이썬프로그램실행하기\n",
      "13 파이썬으로슬랙(slack)메신저에글쓰기\n",
      "14 웹사이트변경사항주기적으로체크해서,메신저로알람주기\n",
      "15 네이버API사용해서,블로그에글쓰기\n",
      "16 자동으로쿠팡파트너스API로가져온상품정보,네이버블로그/트위터에홍보하기\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://crawlingtest.netlify.app/\")\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "titles = soup.find_all(\"li\",\"course\")\n",
    "\n",
    "for index, title in enumerate(titles) : \n",
    "    print(index+1, title.get_text().split(\"-\")[1].replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\"[\")[0])    # 프로그래밍 언어 타입 中 enum은 어떤 형태의 자료든 count를 해주는 기능\n",
    "                                                                                                              # enum은 enumerate에서 파생된 단어\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79afd0a-8c85-402a-b2d3-cda0477f80aa",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
